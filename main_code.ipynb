{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56a619fa",
   "metadata": {},
   "source": [
    "# Deep DeePC Main Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfed4265",
   "metadata": {},
   "source": [
    "## 1. Deep DeePC Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7b7b02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import scipy\n",
    "\n",
    "import cvxpy as cp\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbaefc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreenhouseParams:\n",
    "    def __init__(self):\n",
    "        self.params = {}\n",
    "        self._initialize_params()\n",
    "\n",
    "    def _initialize_params(self):\n",
    "        # Control parameters\n",
    "        self.params[\"nx\"] = 5  # Number of state variables\n",
    "        self.params[\"nu\"] = 7  # Number of control inputs\n",
    "        self.params[\"nd\"] = 3  # Number of disturbances (e.g., outdoor weather)\n",
    "        self.params[\"N_v\"] = 2  # VAR Order for weather prediction model\n",
    "\n",
    "        # Cost function parameters\n",
    "        self.params[\"cc_e\"] = 0.2051             # Electricity cost [$/kWh]\n",
    "        self.params[\"cc_h\"] = 1.43e-2             # Water cost [$/kg]\n",
    "        self.params[\"cc_c\"] = 2e-1                # CO2 cost [$/kg]   [Chen2022appeng]\n",
    "        self.params[\"cc_dw\"] = 4.44444            # Dry weight price of lettuce [$/kg]\n",
    "        self.params[\"c_dehum_eev\"] = 3.0         # Dehumidification cost [kg / kWh]\n",
    "        \n",
    "        self.params[\"q1\"] = 5e+1                  # Weight for state tracking in cost function\n",
    "        self.params[\"q2\"] = 1e+0                  # Regularization weight for control inputs\n",
    "        self.params[\"q3\"] = 1e+2                  # Regularization weight for crop dry weight\n",
    "        \n",
    "        # Hyperparameters for control inputs\n",
    "        self.params[\"u_min\"] = 0  # \n",
    "        self.params[\"u_max\"] = 1  #\n",
    "        self.params[\"du_min\"] = -0.05 # [Svensen2024]\n",
    "        self.params[\"du_max\"] = 0.05  #\n",
    "        \n",
    "        self.params[\"u_fan_max\"] = 1e-2   # Max fan speed [m/s] [Benjamin2024natfood]\n",
    "        self.params[\"u_dehum_max\"] = 2e-5   # Max fan speed [kg/m²/s] [Benjamin2024natfood]\n",
    "        self.params[\"u_pad_max\"] = 5e-3 # maximum airflow rate through the pad [m/s] (Considering that 0.005 [m/s] * A_v ())\n",
    "        \n",
    "        self.params[\"phi_co2_max\"] = 4e-6 # 4.6e-6 # Previous value: 2e-2 # Max CO2 injection rate [kg/m²/s] [Benjamin2024natfood]\n",
    "        self.params[\"P_heat\"] = 100       # Heating power for direct air heater [W/m²]\n",
    "        self.params[\"c_COP\"] = 3          # coefficient of performance \n",
    "        self.params[\"P_light\"] = 100      # Lighting power [W/m²]\n",
    "        self.params[\"P_fan\"] = 20         # Fan system power [W/m²]\n",
    "        self.params[\"P_fog\"] = 10         # Fogging system power [W/m²]\n",
    "        self.params[\"C_out\"] = 400        # Outdoor CO2 concentration [ppm]\n",
    "        \n",
    "        self.params[\"c_lamp\"] = 0.52    # Efficiency of the lamp heating system [Graamans2020appeng], [Benjamin2024natfood]\n",
    "        self.params[\"fan_eff\"] = 1000 * 0.00047194745 * 15 # 7.07921175 [m³/s/kW]\n",
    "        self.params[\"pad_eff\"] = 10     # Cooling pad efficiency [m³/s/kW]: usually 7 ~ 15\n",
    "        \n",
    "        # Cooling Pad Coefficients\n",
    "        self.params[\"eta_p\"] = 0.8       # pad efficiency [-]\n",
    "        \n",
    "        # Environmental constraints for daytime and nighttime\n",
    "        self.params[\"Ti_min_day\"] = 22        # Min daytime temperature [°C]\n",
    "        self.params[\"Ti_max_day\"] = 28        # Max daytime temperature [°C]\n",
    "        self.params[\"RHi_min_day\"] = 60       # Min daytime humidity [%]\n",
    "        self.params[\"RHi_max_day\"] = 85       # Max daytime humidity [%]\n",
    "        self.params[\"Ci_min_day_ppm\"] = 1000  # Min daytime CO2 concentration [ppm]\n",
    "        self.params[\"Ci_max_day_ppm\"] = 1400  # Min daytime CO2 concentration [ppm]\n",
    "        self.params[\"Dw_min\"] = 0             # Min Crop dry weight [kg/m²]\n",
    "\n",
    "        self.params[\"Ti_min_night\"] = 18      # Min nighttime temperature [°C]\n",
    "        self.params[\"Ti_max_night\"] = 24      # Max nighttime temperature [°C]\n",
    "        \n",
    "        self.params[\"RHi_min_night\"] = 50     # Min nighttime humidity [%]\n",
    "        self.params[\"RHi_max_night\"] = 75     # Max nighttime humidity [%]\n",
    "        \n",
    "        self.params[\"Ci_min_night_ppm\"] = 400  # Min daytime CO2 concentration [ppm]\n",
    "        self.params[\"Ci_max_night_ppm\"] = 1000 # Min daytime CO2 concentration [ppm]\n",
    "        self.params[\"Dw_max\"] = 1e1         # Max Crop dry weight [kg/m²]\n",
    "\n",
    "        # Greenhouse construction parameters\n",
    "        self.params[\"w\"] = 10.4  # Greenhouse width [m]\n",
    "        self.params[\"l\"] = 6.4   # Greenhouse length [m]\n",
    "        self.params[\"h\"] = 5     # Greenhouse height [m]\n",
    "        self.params[\"V\"] = self.params[\"w\"] * self.params[\"l\"] * self.params[\"h\"]  # Greenhouse volume [m³]\n",
    "        \n",
    "        self.params[\"r_veg\"] = 0.8   # Vegetation area ratio\n",
    "        self.params[\"A_c\"] = (np.pi * self.params[\"l\"] * self.params[\"w\"] / 2) + 2 * (self.params[\"w\"] * self.params[\"h\"])  # Cover area [m²] (Assume: Single-span semi-cylindrical (Quonset) Greenhouse)\n",
    "        self.params[\"A_s\"] = self.params[\"w\"] * self.params[\"l\"]        # Surface area [m²]\n",
    "        self.params[\"A_v\"] = self.params[\"A_s\"] * self.params[\"r_veg\"]  # Vegetation area [m²]\n",
    "        self.params[\"A_p\"] = 5                                          # Cooling pad area [m²]\n",
    "\n",
    "        # Heat transfer equation [Lin2021appeng], [Benjamin2024natfood]\n",
    "        self.params[\"T_abs\"] = 273.15     # Absolute temperature [°C]\n",
    "        self.params[\"L_v\"] = 2256.4       # Latent heat of evaporation [J/g]\n",
    "        self.params[\"k_cap_q\"] = 3e4    # Heat capacity [J/m²/°C]\n",
    "        self.params[\"k_cap_q_v\"] = 1290 # Heat transfer coefficient [W/m²/°C]\n",
    "        self.params[\"k_cap_h\"] = (self.params[\"V\"] / self.params[\"A_v\"]) # Mass capacity for humidity [m]\n",
    "        self.params[\"k_cap_c\"] = (self.params[\"V\"] / self.params[\"A_v\"]) # Mass capacity for CO2 [m]\n",
    "        \n",
    "        self.params[\"rho_i\"] = 1.225    # Internal air density [kg/m³]\n",
    "        self.params[\"c_i\"] = 1000       # Heat capacity of internal air [J/kg/°C]\n",
    "        self.params[\"alpha1\"] = 0.7     # transmission coefficient of cover material [-]\n",
    "        self.params[\"c_cov\"] = 0.3 # heat transfer coefficient of cover material [W/m²/°C] [Benjamin2024natfood]\n",
    "\n",
    "        # coefficient of pad cooling equation [J/m³/K]\n",
    "        self.params[\"K_p\"] = (self.params[\"A_v\"] / self.params[\"A_p\"]) * self.params[\"rho_i\"] * self.params[\"c_i\"]\n",
    "        \n",
    "        # Mass balance equation\n",
    "        self.params[\"p_gc\"] = 1.8e-3  # Mass balance parameter [m*C^(-1/3)/s]\n",
    "        self.params[\"m_co2\"] = 0.04401  # Molar mass of CO2 [mg/µmol]\n",
    "        self.params[\"m_carb\"] = 30e-3    # Molar mass of carbohydrates [mg/µmol]\n",
    "        self.params[\"r_b\"] = 150         # Boundary layer resistance [s/m]\n",
    "        self.params[\"gamma\"] = 8e-3      # CO2 compensation point\n",
    "        \n",
    "        self.params[\"c_a_pl\"] = 62.8 # [m^2/kg]\n",
    "        self.params[\"c_v_pl_ai\"] = 3.6E-3 # mass transfer coefficient [m/s] [Stanghellini1987]\n",
    "        self.params[\"c_v_0\"] = 0.85 # Calibration parameter [-]\n",
    "        self.params[\"c_v_1\"] = 611 # [J/m^3] [Goudriaan1977]\n",
    "        self.params[\"c_v_2\"] = 17.4 # [-] [Goudriaan1977]\n",
    "        self.params[\"c_v_3\"] = 239 # [°C] [Goudriaan1977]\n",
    "        self.params[\"mw_water\"] = 18 # molecular mass of water [kg/kmol]\n",
    "        self.params[\"c_R\"] = 8314 # gas constant [J/K/kmol]\n",
    "        \n",
    "        # Two-state crop model for lettuce (Van Hanten)\n",
    "        self.params[\"c_alpha\"] = 0.68 # physical  [-]\n",
    "        self.params[\"c_beta\"] = 0.8\n",
    "        self.params[\"c_co2_1\"] = 5.11e-6\n",
    "        self.params[\"c_co2_2\"] = 2.30e-6\n",
    "        self.params[\"c_co2_3\"] = 6.29e-4\n",
    "        self.params[\"c_gamma\"] = 5.2e-5\n",
    "        \n",
    "        self.params[\"c1\"] = 3.55e-9\n",
    "        self.params[\"c_lar_d\"] = 62.5e-3\n",
    "        self.params[\"c_lar_s\"] = 75 # 75E-3? shoot structural leaf area ratio [1/m^2/kg]\n",
    "        self.params[\"c_tau\"] = 0.07\n",
    "        self.params[\"c_k\"] = 0.9\n",
    "        self.params[\"c_bnd\"] = 0.004\n",
    "        self.params[\"c_pld\"] = 53\n",
    "        \n",
    "        self.params[\"c_r_gr_max\"] = 5E-6 # [1/s]\n",
    "        self.params[\"c_Q10_gr\"] = 1.6 # Q10-factor for the maintenance respiration [-]\n",
    "        self.params[\"c_Q10_resp\"] = 2.0 # Q10-factor for the maintenance respiration [-]\n",
    "        self.params[\"c_Q10_Gamma\"] = 2 # [-]\n",
    "        self.params[\"c_resp_s\"] = 3.47E-7 # maintenance respiration rates for the shoot [1/s]\n",
    "        self.params[\"c_resp_r\"] = 1.16E-7 # maintenance respiration rates for the root [1/s]\n",
    "        self.params[\"c_par\"] = 1 # [-]\n",
    "        self.params[\"c_rad_rf\"] = 1 # [-]\n",
    "        self.params[\"c_eps\"] = 17E-9 # light use efficiency at very high CO2 [kg/J] [Goudriaan1985]\n",
    "        self.params[\"c_Gamma\"] = 7.32E-5 # [kg/m^3] [Goudriaan1985]\n",
    "        self.params[\"c_car_1\"] = -1.32E-5 # carboxylation resistance fitting parameters 1 [m/s/C^2] [Goudriaan1987]\n",
    "        self.params[\"c_car_2\"] =  5.94E-4 # carboxylation resistance fitting parameters 2 [m/s/C] [Goudriaan1987]\n",
    "        self.params[\"c_car_3\"] = -2.64E-3 # carboxylation resistance fitting parameters 3 [m/s] [Goudriaan1987]\n",
    "        \n",
    "        self.params[\"c_bnd\"] = 0.004 # boundary layer conductance [m/s]\n",
    "        self.params[\"c_stm\"] = 0.007 # stomatal conductance [m/s]\n",
    "        self.params[\"c_tau\"] = 0.07 # ratio of the root dry weight to the total crop dry weight (measurement)\n",
    "        self.params[\"c_k\"] = 0.9 #\n",
    "        \n",
    "        self.params[\"Hi_min_day\"] = (self.params[\"RHi_min_day\"] / 100) * ( (1.0272 * self.params[\"Ti_min_day\"] - 1.8959) * 1E-3 )   # Min daytime absolute humidity [kg/m^3]\n",
    "        self.params[\"Hi_max_day\"] = (self.params[\"RHi_max_day\"] / 100) * ( (1.0272 * self.params[\"Ti_max_day\"] - 1.8959) * 1E-3 )   # Min daytime absolute humidity [kg/m^3]\n",
    "        self.params[\"Hi_min_night\"] = (self.params[\"RHi_min_night\"] / 100) * ( (1.0272 * self.params[\"Ti_min_night\"] - 1.8959) * 1E-3 )   # Min daytime absolute humidity [kg/m^3]\n",
    "        self.params[\"Hi_max_night\"] = (self.params[\"RHi_max_night\"] / 100) * ( (1.0272 * self.params[\"Ti_max_night\"] - 1.8959) * 1E-3 )   # Min daytime absolute humidity [kg/m^3]\n",
    "        \n",
    "        self.params[\"Ci_min_day\"] = self.params[\"Ci_min_day_ppm\"] * (self.params[\"m_co2\"]/24.45) * 1E-3     # Min daytime CO2 [kg/m³]\n",
    "        self.params[\"Ci_max_day\"] = self.params[\"Ci_max_day_ppm\"] * (self.params[\"m_co2\"]/24.45) * 1E-3     # Max daytime CO2 [kg/m³]\n",
    "        self.params[\"Ci_min_night\"] = self.params[\"Ci_min_night_ppm\"] * (self.params[\"m_co2\"]/24.45) * 1E-3 # Min nighttime CO2 [kg/m³]\n",
    "        self.params[\"Ci_max_night\"] = self.params[\"Ci_max_night_ppm\"] * (self.params[\"m_co2\"]/24.45) * 1E-3 # Max nighttime CO2 [kg/m³]\n",
    "        \n",
    "        \n",
    "    def get_param(self, key):\n",
    "        return self.params.get(key, None)\n",
    "\n",
    "    def set_param(self, key, value):\n",
    "        self.params[key] = value\n",
    "        \n",
    "    def set_initial(self):\n",
    "        self.params[\"Ti_0\"] = 20.0                       # unit: [°C]\n",
    "        self.params[\"RHi_0\"] = 60                        # unit: [%]\n",
    "        \n",
    "        self.params[\"Hi_sat_0\"] = (1.0272 * self.params[\"Ti_0\"] - 1.8959) * 1E-3\n",
    "        self.params[\"Hi_0\"] = (self.params[\"RHi_0\"] / 100) * self.params[\"Hi_sat_0\"] # unit: [kg/m^3]\n",
    "        self.params[\"Ci_0\"] = 400.0 * (0.04401 / 24.45) * 1E-3  # unit change: [ppm] -> [kg/m³]\n",
    "        self.params[\"Dn_0\"] = 0.72E-3 * 0.25 # [kg/m^2] # Zhang and Kacira (2020)\n",
    "        self.params[\"Ds_0\"] = 0.72E-3 * 0.75 # [kg/m^2] # Zhang and Kacira (2020)\n",
    "        \n",
    "        x0 = np.array([self.params[\"Ti_0\"], self.params[\"Hi_0\"], self.params[\"Ci_0\"], self.params[\"Dn_0\"], self.params[\"Ds_0\"]], dtype=float)\n",
    "        u0 = np.array(np.zeros((self.params[\"nu\"], 1)))\n",
    "        \n",
    "        return x0, u0\n",
    "    \n",
    "    def set_min_max(self):\n",
    "        x_min_day = np.array([self.params[\"Ti_min_day\"], self.params[\"Hi_min_day\"], self.params[\"Ci_min_day\"], self.params[\"Dw_min\"], self.params[\"Dw_min\"]], dtype=float)\n",
    "        x_max_day = np.array([self.params[\"Ti_max_day\"], self.params[\"Hi_max_day\"], self.params[\"Ci_max_day\"], self.params[\"Dw_max\"], self.params[\"Dw_max\"]], dtype=float)\n",
    "        \n",
    "        x_min_night = np.array([self.params[\"Ti_min_night\"], self.params[\"Hi_min_night\"], self.params[\"Ci_min_night\"], self.params[\"Dw_min\"], self.params[\"Dw_min\"]], dtype=float)\n",
    "        x_max_night = np.array([self.params[\"Ti_max_night\"], self.params[\"Hi_max_night\"], self.params[\"Ci_max_night\"], self.params[\"Dw_max\"], self.params[\"Dw_max\"]], dtype=float)\n",
    "        \n",
    "        return x_min_day, x_max_day, x_min_night, x_max_night\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5f8bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropClimateModel:\n",
    "    def __init__(self, greenhouse_params):\n",
    "        self.p = greenhouse_params  # So we can access p.get_param(\"rho_i\"), etc.\n",
    "\n",
    "    def cc_model_gh(self, t, x, u, o):\n",
    "        # Unpack states: Dn (Non-structural dry weight), Ds (Structural dry weight)\n",
    "        Ti, Hi, Ci, Dn, Ds = x # Dn, Ds unit: [kg/m²]\n",
    "        \n",
    "        # Unpack controls\n",
    "        u_heat, u_pad, u_blind, u_light, u_fan, u_dehum, u_co2 = u\n",
    "\n",
    "        # Unpack outdoor disturbances\n",
    "        To, Ho, Io = o\n",
    "        Co = self.p.get_param(\"C_out\") * (0.04401 / 24.45) * 1E-3 # unit change: [ppm] -> [kg/m³]\n",
    "        \n",
    "        # Retrieve parameters from GreenhouseParams\n",
    "        w_sigma     = self.p.get_param(\"w_sigma\")  # noise covariance (3x3)\n",
    "        \n",
    "        k_cap_q = self.p.get_param(\"k_cap_q\")\n",
    "        k_cap_q_v = self.p.get_param(\"k_cap_q_v\")\n",
    "        k_cap_h = self.p.get_param(\"k_cap_h\")\n",
    "        k_cap_c = self.p.get_param(\"k_cap_c\")\n",
    "        \n",
    "        T_abs       = self.p.get_param(\"T_abs\")  # \n",
    "        L_v         = self.p.get_param(\"L_v\")    # latent heat of evaporation [J/g]\n",
    "        alpha1      = self.p.get_param(\"alpha1\")\n",
    "        c_cov       = self.p.get_param(\"c_cov\")\n",
    "        A_c         = self.p.get_param(\"A_c\")\n",
    "        A_v         = self.p.get_param(\"A_v\")\n",
    "        \n",
    "        P_light     = self.p.get_param(\"P_light\")\n",
    "        c_lamp      = self.p.get_param(\"c_lamp\")\n",
    "        phi_co2_max = self.p.get_param(\"phi_co2_max\")\n",
    "        u_fan_max   = self.p.get_param(\"u_fan_max\")\n",
    "        u_dehum_max = self.p.get_param(\"u_dehum_max\")\n",
    "        u_pad_max   = self.p.get_param(\"u_pad_max\") \n",
    "        # u_fog_max   = self.p.get_param(\"u_fog_max\")\n",
    "        P_heat      = self.p.get_param(\"P_heat\")\n",
    "        p_gc        = self.p.get_param(\"p_gc\")\n",
    "        \n",
    "        # Mass balance equation parameters (Crop canopy transpiration)\n",
    "        c_a_pl = self.p.get_param(\"c_a_pl\")\n",
    "        c_v_pl_ai = self.p.get_param(\"c_v_pl_ai\")\n",
    "        c_v_0 = self.p.get_param(\"c_v_0\")\n",
    "        c_v_1 = self.p.get_param(\"c_v_1\")\n",
    "        c_v_2 = self.p.get_param(\"c_v_2\")\n",
    "        c_v_3 = self.p.get_param(\"c_v_3\")\n",
    "        mw_water = self.p.get_param(\"mw_water\")\n",
    "        c_R = self.p.get_param(\"c_R\")\n",
    "        \n",
    "        # Two state Crop model parameters\n",
    "        c_alpha = self.p.get_param(\"c_alpha\")\n",
    "        c_beta  = self.p.get_param(\"c_beta\")\n",
    "        c_r_gr_max = self.p.get_param(\"c_r_gr_max\")\n",
    "        c_Q10_gr = self.p.get_param(\"c_Q10_gr\")\n",
    "        c_Q10_resp = self.p.get_param(\"c_Q10_resp\")\n",
    "        c_Q10_Gamma   = self.p.get_param(\"c_Q10_Gamma\")\n",
    "        \n",
    "        c_resp_s = self.p.get_param(\"c_resp_s\")\n",
    "        c_resp_r = self.p.get_param(\"c_resp_r\")\n",
    "        c_par = self.p.get_param(\"c_par\")\n",
    "        c_rad_rf = self.p.get_param(\"c_rad_rf\")\n",
    "        c_lar_s = self.p.get_param(\"c_lar_s\")\n",
    "        c_eps   = self.p.get_param(\"c_eps\")\n",
    "        c_Gamma   = self.p.get_param(\"c_Gamma\")\n",
    "        \n",
    "        c_car_1   = self.p.get_param(\"c_car_1\")\n",
    "        c_car_2   = self.p.get_param(\"c_car_2\")\n",
    "        c_car_3   = self.p.get_param(\"c_car_3\")\n",
    "        \n",
    "        c_bnd   = self.p.get_param(\"c_bnd\")\n",
    "        c_stm   = self.p.get_param(\"c_stm\")\n",
    "        \n",
    "        c_tau   = self.p.get_param(\"c_tau\")\n",
    "        c_k     = self.p.get_param(\"c_k\")\n",
    "        \n",
    "        eta_p = self.p.get_param(\"eta_p\")\n",
    "        K_p = self.p.get_param(\"K_p\")\n",
    "        \n",
    "        # Generate process noise, akin to MATLAB's mvnrnd(zeros, w_sigma)\n",
    "        # w = np.random.multivariate_normal(mean=np.zeros(nx), cov=w_sigma)\n",
    "\n",
    "        # 1) Heat transfer\n",
    "        Q_sol  = alpha1 * (1 - u_blind) * Io * 1E-1\n",
    "        Q_lamp = (1 - c_lamp) * P_light * u_light\n",
    "        Q_heat = P_heat * u_heat\n",
    "        \n",
    "        # 1-1) Heat flux via cooling pad\n",
    "        Ho_sat = (1.0272 * To - 1.8959) * 1E-3 # [Hu2023appeng]\n",
    "        RHo = (Ho / Ho_sat) * 100 # outdoor relative humidity [%]\n",
    "        T_wb = self.T_wb_calculation(To, RHo)             # Wet bulb temperature \n",
    "        Tp = To - self.p.get_param(\"eta_p\") * (To - T_wb) # Cooling pad temperature\n",
    "        Q_cool = K_p * u_pad_max * (Tp - Ti) * u_pad      # heat flux by cooling pad [W/m²]\n",
    "        \n",
    "        # 1-2) Total light intensity to canopy\n",
    "        # I_total = Q_sol + (c_lamp * P_light * u_light) # [W/m^2]\n",
    "        I_total = alpha1 * (1 - u_blind) * Io + (c_lamp * P_light * u_light) # [W/m^2]\n",
    "\n",
    "        # 2) Humidity saturation\n",
    "        # Hi_sat = ((c_v_1 * mw_water)/(c_R * (Ti + T_abs))) * np.exp((c_v_2 * Ti)/(Ti + c_v_3)) # [kg/m^3]\n",
    "        Hi_sat = (1.0272 * Ti - 1.8959) * 1e-3 # [kg/m^3]\n",
    "        \n",
    "        # 3) Canopy Transpiration (Heat, Mass)\n",
    "        H_transp = (1 - np.exp(-c_a_pl * Ds)) * c_v_pl_ai * ( (c_v_0 * Hi_sat) - Hi ) # [kg/m^2/s]\n",
    "        Q_trans = L_v * 1e3 * H_transp\n",
    "\n",
    "        # 4) Ventilation (Heat, Mass)\n",
    "        # Q_vent = (1 / self.p.get_param(\"A_s\")) * rho_i * c_i * (Ti - To) * u_fan_max * u_fan\n",
    "        Q_vent = k_cap_q_v * (Ti - To) * u_fan_max * u_fan\n",
    "        H_vent  = (Hi - Ho) * u_fan_max * u_fan\n",
    "\n",
    "        # 4-1) Dehumidification\n",
    "        H_dehum = u_dehum_max * u_dehum # [kg/m²/s]\n",
    "        \n",
    "        # 5) Cover effect (Heat, Mass)\n",
    "        if Ti <= To:\n",
    "            g_c = 0\n",
    "        else:\n",
    "            g_c = p_gc * (Ti - To) ** (1 / 3)\n",
    "\n",
    "        Q_cov  = c_cov * (A_c/A_v) * (Ti - To) # [Benjamin2024natfood]\n",
    "        H_cov   = g_c * (0.2522 * np.exp(0.0485 * Ti) * 1E-3 * (Ti - To) - (Hi_sat - Hi)) # [kg/m^3]\n",
    "\n",
    "        # 6-1) Single-state Crop Model (Van Henten)s\n",
    "        # Dw_numerator = c1*I_total * (-c_co2_1*Ti ** 2 + c_co2_2*Ti - c_co2_3) * (Ci - c_gamma)\n",
    "        # DW_denominator = c1*I_total + (-c_co2_1*Ti ** 2 + c_co2_2*Ti - c_co2_3) * (Ci - c_gamma)\n",
    "        # dDw_dt = (c_alpha * c_beta) * (1-np.exp(-c_pld*Dw)) * (Dw_numerator / DW_denominator) - c_resp1 * Dw * 2 ** (0.1*(Ti-25))\n",
    "        \n",
    "        # 6-2) Two-state Crop Model (Van Henten, 1994)\n",
    "        Gamma = c_Gamma * c_Q10_Gamma ** ((Ti - 20)/10) # \n",
    "        eps = c_eps * ((Ci - Gamma) / (Ci + 2*Gamma)) # \n",
    "        sigma_car = c_car_1 * Ti ** 2 + c_car_2 * Ti + c_car_3 # carboxylation conductance [m/s]\n",
    "        sigma_CO2 = 1/((1/c_bnd) + (1/c_stm) + (1/sigma_car)) # canopy conductance [m/s]\n",
    "        \n",
    "        r_gr = c_r_gr_max * (Dn/(Ds + Dn)) * (c_Q10_gr) ** ((Ti - 20)/10)\n",
    "        phi_resp = (c_resp_s * (1-c_tau) + c_resp_r * c_tau) * Ds * c_Q10_resp ** ((Ti - 25)/10)\n",
    "        phi_phot_max = (eps * c_par * c_rad_rf * I_total * sigma_CO2 * (Ci - Gamma)) / (eps * c_par * c_rad_rf * I_total + sigma_CO2 * (Ci - Gamma)) # response of canopy photosynthesis [kg/m^2/s]\n",
    "        phi_phot = phi_phot_max * (1 - np.exp(-c_k * c_lar_s * (1-c_tau) * Ds)) #\n",
    "\n",
    "        # 7) CO2 injection & ventilation\n",
    "        C_inj  = phi_co2_max * u_co2\n",
    "        C_vent = (Ci - Co) * u_fan_max * u_fan\n",
    "        C_pho  = phi_phot - (1/c_alpha) * phi_resp - ((1-c_beta)/(c_alpha*c_beta)) * r_gr * Ds # unit change: [umol/m²/s] -> [lg/m³]\n",
    "        \n",
    "        \n",
    "        # 8) ODEs\n",
    "        dTi_dt = (1 / k_cap_q) * (Q_sol + Q_lamp - Q_cov - Q_trans - Q_vent + Q_heat + Q_cool) # [°C/m^2/s]\n",
    "        dHi_dt = (1 / k_cap_h) * (H_transp - H_cov - H_vent - H_dehum)                         # [kg/m^3/s]\n",
    "        dCi_dt = (1 / k_cap_c) * (C_inj - C_vent - C_pho)                                      # [kg/m^3/s]\n",
    "        dDn_dt = c_alpha * phi_phot - r_gr * Ds - phi_resp - ((1-c_beta)/c_beta) * r_gr * Ds   # [kg/m^2/s]\n",
    "        dDs_dt = r_gr * Ds # [kg/m^2/s]\n",
    "        \n",
    "        \n",
    "        dxdt = np.array([dTi_dt, dHi_dt, dCi_dt, dDn_dt, dDs_dt])  # + w add process noise\n",
    "        return dxdt\n",
    "    \n",
    "    \n",
    "    # RK4 integrator for cc_model_gh.\n",
    "    def rk4_gh(self, t, dt, xk, uk, ok): \n",
    "        k1 = self.cc_model_gh(t,          xk,              uk, ok)\n",
    "        k2 = self.cc_model_gh(t + 0.5*dt, xk + 0.5*dt*k1,  uk, ok)\n",
    "        k3 = self.cc_model_gh(t + 0.5*dt, xk + 0.5*dt*k2,  uk, ok)\n",
    "        k4 = self.cc_model_gh(t + dt,     xk + dt*k3,      uk, ok)\n",
    "        \n",
    "        k_sum = k1 + 2*k2 + 2*k3 + k4\n",
    "        \n",
    "        return k_sum\n",
    "        \n",
    "    def T_wb_calculation(self, T_o, RH_o): # based on wet bulb calculator\n",
    "        T_wb = T_o * np.arctan(0.151977 * np.sqrt(RH_o + 8.313659)) \\\n",
    "                + 0.00391838 * np.sqrt( RH_o ** 3 ) * np.arctan(0.023101 * RH_o) \\\n",
    "                    -np.arctan(RH_o - 1.676331) + np.arctan(T_o + RH_o) -4.686035\n",
    "        \n",
    "        return T_wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbefde35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "import cvxpy as cp\n",
    "\n",
    "class DiffQPLayer:\n",
    "    def __init__(self, params, device=\"cpu\"):\n",
    "        self.device = device\n",
    "        self.K = params[\"K\"]\n",
    "        self.m = 2 * (params[\"ny\"] * params[\"T_f\"]) # both state and input constraints\n",
    "        \n",
    "        # Define the QP problem parametrically\n",
    "        g = cp.Variable((self.K, 1))  # Optimization variable\n",
    "        f = cp.Parameter((self.K, 1))  # Linear term (from DNN)\n",
    "        A = cp.Parameter((self.m, self.K))  # Constraint matrix\n",
    "        b = cp.Parameter((self.m, 1))  # Constraint bounds\n",
    "        H = 2 * torch.eye(self.K, dtype=torch.float32, device=device).numpy()  # Constant H\n",
    "        \n",
    "        objective = cp.Minimize(0.5 * cp.quad_form(g, H) + f.T @ g)\n",
    "        constraints = [A @ g <= b]\n",
    "        problem = cp.Problem(objective, constraints)\n",
    "        \n",
    "        # Create differentiable layer\n",
    "        self.qp_layer = CvxpyLayer(problem, parameters=[f, A, b], variables=[g]) # ignore_dpp=True, solver_args=solver_args\n",
    "    \n",
    "    def forward(self, f, A, b):\n",
    "        # Ensure inputs are in the right shape and on the correct device\n",
    "        f = f.reshape(-1, self.K, 1).to(self.device)  # (batch, K, 1)\n",
    "        A = A.reshape(-1, self.m, self.K).to(self.device)  # (batch, m, K)\n",
    "        b = b.reshape(-1, self.m, 1).to(self.device)  # (batch, m, 1)\n",
    "        \n",
    "        # Use ignore_dpp=True and set solver options\n",
    "        solver_args = {\n",
    "            \"max_iters\": 5000,  # Increase iterations for better accuracy\n",
    "            \"eps\": 1e-8,        # Tighten tolerance\n",
    "            # \"warm_starts\": True,\n",
    "            \"verbose\": False    # Suppress solver output\n",
    "        }\n",
    "        \n",
    "        # Solve QP and get solution\n",
    "        g_star, = self.qp_layer(f, A, b, solver_args=solver_args)\n",
    "        \n",
    "        return g_star  # (batch, K, 1)\n",
    "    \n",
    "    def __call__(self, f, A, b):\n",
    "        return self.forward(f, A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc312ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import block_diag\n",
    "\n",
    "class DeepDeePC:\n",
    "    def __init__(self, greenhouse_params, params, dnn_model, device=\"cpu\"):\n",
    "        self.p = greenhouse_params\n",
    "        self.params = params\n",
    "        self.dnn = dnn_model.to(device)\n",
    "        self.diff_qp_layer = DiffQPLayer(params, device=device)\n",
    "        self.device = device\n",
    "        \n",
    "    def compute_stage_cost(self, u, dt):\n",
    "        # Retrieve parameters\n",
    "        cc_e = self.p.get_param(\"cc_e\")          # Electricity cost [$ / kWh]\n",
    "        cc_c = self.p.get_param(\"cc_c\")          # CO2 cost [$ / kg]\n",
    "        c_COP = self.p.get_param(\"c_COP\")         # Coefficient of performance (unused here)\n",
    "        c_dehum_eev = self.p.get_param(\"c_dehum_eev\")  # Dehumidification cost [kg / kWh]\n",
    "        \n",
    "        P_heat   = self.p.get_param(\"P_heat\")     # [W/m²]\n",
    "        P_light  = self.p.get_param(\"P_light\")    # [W/m²]\n",
    "        fan_eff  = self.p.get_param(\"fan_eff\")    # [m^3/s/kW] (unused here)\n",
    "        A_s  = self.p.get_param(\"A_s\")            # Surface area [m²] (not used in computation below)\n",
    "        A_p  = self.p.get_param(\"A_p\")            # Cooling pad surface [m²]\n",
    "        pad_eff = self.p.get_param(\"pad_eff\")   # [m^3/s/kW]\n",
    "        u_fan_max  = self.p.get_param(\"u_fan_max\")\n",
    "        u_dehum_max = self.p.get_param(\"u_dehum_max\")\n",
    "        u_pad_max = self.p.get_param(\"u_pad_max\")\n",
    "        phi_co2_max = self.p.get_param(\"phi_co2_max\")  # [kg/m²/s]\n",
    "        \n",
    "        # Handle single sample (1D) or batch (2D) input uniformly\n",
    "        is_single = (u.ndim == 1)\n",
    "        if is_single:\n",
    "            u = u[None, :]  # Convert to shape (1, n)\n",
    "\n",
    "        # Check the dimensionality of u and compute accordingly.\n",
    "        C_heat  = 1E-3 * (dt / 3600) * P_heat  * u[:, 0]                    # Heating cost  [kWh/m²] \n",
    "        C_cool  = (A_p / A_s) * (dt / 3600) * u_pad_max * u[:, 1] / fan_eff # Cooling cost  [kWh/m²] \n",
    "        C_blind = 0.0 * u[:, 2]                                             # Blind/pad cost (assume zero if not used)\n",
    "        C_light = 1E-3 * (dt / 3600) * P_light * u[:, 3]                    # Lighting cost [kWh/m²]\n",
    "        C_fan   = (dt / 3600) * u_fan_max * u[:, 4]                         # Fan cost      [kWh/m²] # C_fan = (dt/3600) / fan_eff * u_fan_max * u[3]\n",
    "        C_dehum = dt * u_dehum_max * u[:, 5] / c_dehum_eev                  # Dehumification cost [kWh/m²]\n",
    "\n",
    "        C_elec  = (C_heat + C_cool + C_light + C_fan + C_dehum + C_blind)   # Total electric energy per unit area\n",
    "        C_co2   = dt * phi_co2_max * u[:, 6]                                # CO2 cost [kg/m²]\n",
    "\n",
    "        # Sum all cost components\n",
    "        C_total = cc_e * C_elec + cc_c * C_co2\n",
    "        return C_total\n",
    "    \n",
    "    def build_hankel_matrices(self, x, u):\n",
    "        T = self.params[\"T\"]\n",
    "        T_p = self.params[\"T_p\"]\n",
    "        L = self.params[\"L\"]  # L = T_p + T_f\n",
    "        K = self.params[\"K\"]\n",
    "        \n",
    "        # For simplicity, let's define y := x if x is indeed the greenhouse output.\n",
    "        y = x  # if x is your measured output. Adjust as needed.\n",
    "\n",
    "        # Initialize Hankel blocks:\n",
    "        Up = [] #   Up  in R^(nu*Tp, K)\n",
    "        Uf = [] #   Uf  in R^(nu*Tf, K)\n",
    "        Yp = [] #   Yp  in R^(ny*Tp, K)\n",
    "        Yf = [] #   Yf  in R^(ny*Tf, K)\n",
    "\n",
    "        # Stack row by row for each time step in the horizon. \n",
    "        for col in range(K):\n",
    "            # A snippet from 'col' to 'col + L - 1'\n",
    "            u_block = u[col: col + L, :]  # shape (L, nu)\n",
    "            y_block = y[col: col + L, :]  # shape (L, ny)\n",
    "\n",
    "            # Past = first Tp rows\n",
    "            u_past = u_block[:T_p, :]  # shape (Tp, nu)\n",
    "            y_past = y_block[:T_p, :]  # shape (Tp, ny)\n",
    "\n",
    "            # Future = last Tf rows\n",
    "            u_fut = u_block[T_p:, :]   # shape (Tf, nu)\n",
    "            y_fut = y_block[T_p:, :]   # shape (Tf, ny)\n",
    "\n",
    "            # Flatten or stack them as columns:\n",
    "            Up_col = u_past.reshape(-1, 1)  # shape (nu*Tp, 1)\n",
    "            Uf_col = u_fut.reshape(-1, 1)   # shape (nu*Tf, 1)\n",
    "            Yp_col = y_past.reshape(-1, 1)  # shape (ny*Tp, 1)\n",
    "            Yf_col = y_fut.reshape(-1, 1)   # shape (ny*Tf, 1)\n",
    "\n",
    "            if col == 0:\n",
    "                Up = Up_col\n",
    "                Uf = Uf_col\n",
    "                Yp = Yp_col\n",
    "                Yf = Yf_col\n",
    "            else:\n",
    "                Up = np.hstack([Up, Up_col])\n",
    "                Uf = np.hstack([Uf, Uf_col])\n",
    "                Yp = np.hstack([Yp, Yp_col])\n",
    "                Yf = np.hstack([Yf, Yf_col])\n",
    "\n",
    "        return Up, Yp, Uf, Yf\n",
    "    \n",
    "    def set_hankel_matrices(self, Uf, Yf):\n",
    "        \"\"\"A helper to store Uf and Yf for evaluation (if desired).\"\"\"\n",
    "        self.Uf = Uf\n",
    "        self.Yf = Yf\n",
    "    \n",
    "    def _solve_qp_from_dnn(self, input_vec: torch.Tensor, Uf: np.ndarray, Yf: np.ndarray, time_flag):\n",
    "        # (a) Forward through DNN\n",
    "        g_unc = self.dnn(input_vec.to(self.device))    # (batch, K)\n",
    "        batch_size, K = g_unc.shape\n",
    "        dtype = g_unc.dtype\n",
    "\n",
    "        # (b) Build f for the QP: f = -2 * g_unc.unsqueeze(-1)\n",
    "        f = -2 * g_unc.unsqueeze(-1)  # shape=(batch, K, 1)\n",
    "\n",
    "        # (c) Prepare time_flag as a length‐batch tensor\n",
    "        if not torch.is_tensor(time_flag):\n",
    "            time_flag = torch.tensor(time_flag, dtype=dtype, device=self.device).unsqueeze(0)\n",
    "        time_flag = time_flag.reshape(-1)              # (batch,)\n",
    "        if time_flag.dim() == 0:\n",
    "            time_flag = time_flag.unsqueeze(0)\n",
    "\n",
    "        # (d) Use p.set_min_max() to get day/night x_min, x_max\n",
    "        x_min_day, x_max_day, x_min_night, x_max_night = self.p.set_min_max()\n",
    "\n",
    "        x_min_orig = torch.where(\n",
    "            time_flag[:, None] == 1,\n",
    "            torch.as_tensor(x_min_day,   dtype=torch.float32, device=self.device),\n",
    "            torch.as_tensor(x_min_night, dtype=torch.float32, device=self.device),\n",
    "        )  # shape=(batch, ny)\n",
    "\n",
    "        x_max_orig = torch.where(\n",
    "            time_flag[:, None] == 1,\n",
    "            torch.as_tensor(x_max_day,   dtype=torch.float32, device=self.device),\n",
    "            torch.as_tensor(x_max_night, dtype=torch.float32, device=self.device),\n",
    "        )  # shape=(batch, ny)\n",
    "\n",
    "        # (e) Build Δ = X_max_scale − X_min_scale (for all ny)\n",
    "        X_min = torch.as_tensor(self.params[\"x_min_value_scaling\"], dtype=torch.float32, device=self.device)\n",
    "        X_max = torch.as_tensor(self.params[\"x_max_value_scaling\"], dtype=torch.float32, device=self.device)\n",
    "        delta = X_max - X_min  # (ny,)\n",
    "\n",
    "        # (f) Build b_state = [ (x_max_orig − X_min) repeated over T_f;  −(x_min_orig − X_min) ]\n",
    "        T_f = self.params[\"T_f\"]\n",
    "        #  b_pos shape: (batch, ny*T_f)\n",
    "        b_pos = (x_max_orig - X_min) \\\n",
    "                    .unsqueeze(2) \\\n",
    "                    .repeat(1, 1, T_f) \\\n",
    "                    .view(batch_size, -1)\n",
    "        #  b_neg shape: (batch, ny*T_f)\n",
    "        b_neg = -(x_min_orig - X_min) \\\n",
    "                    .unsqueeze(2) \\\n",
    "                    .repeat(1, 1, T_f) \\\n",
    "                    .view(batch_size, -1)\n",
    "        #  Concatenate → (batch, 2*ny*T_f) then unsqueeze to (batch, 2*ny*T_f, 1)\n",
    "        b_state = torch.cat([b_pos, b_neg], dim=1).unsqueeze(-1)\n",
    "\n",
    "        # (g) Build A_state = [ D·Yf; −D·Yf ], where D = diag(delta repeated T_f times)\n",
    "        delta_rep = delta.repeat_interleave(T_f)           # (ny*T_f,)\n",
    "        D = torch.diag(delta_rep).to(self.device)         # (ny*T_f, ny*T_f)\n",
    "\n",
    "        Yf_torch = torch.as_tensor(Yf, dtype=torch.float32, device=self.device)  # (ny*T_f, K)\n",
    "        Yf_orig = D @ Yf_torch                             # (ny*T_f, K)\n",
    "\n",
    "        A_pos = Yf_orig                                     # (ny*T_f, K)\n",
    "        A_state = torch.cat([A_pos, -A_pos], dim=0)         # (2*ny*T_f, K)\n",
    "        # Now duplicate along batch dimension:\n",
    "        A_state_batch = A_state.unsqueeze(0).repeat(batch_size, 1, 1)  # (batch, 2*ny*T_f, K)\n",
    "\n",
    "        # (h) Solve QP: g_star shape = (batch, K, 1)\n",
    "        g_star = self.diff_qp_layer(f, A_state_batch, b_state)\n",
    "        g_star = g_star.squeeze(-1)   # (batch, K)\n",
    "\n",
    "        # If batch_size=1, return a 1D vector of shape (K,)\n",
    "        return g_star.squeeze(0) if batch_size == 1 else g_star\n",
    "    \n",
    "    def predict_gk(self, input_vec, Uf, Yf, time_flag):\n",
    "        self.dnn.eval()\n",
    "        \n",
    "        # forward pass\n",
    "        with torch.no_grad():\n",
    "            pred_g = self.dnn(input_vec)  # Shape: (batch, K)\n",
    "        \n",
    "        return pred_g.squeeze(0)\n",
    "    \n",
    "    def solve_deep_deepc(self, Up, Yp, Uf, Yf, u_ini, y_ini, e_u, e_y, time_feature, time_flag): # , x_min, x_max\n",
    "        \n",
    "        u_ini_tensor = torch.as_tensor(u_ini, dtype=torch.float32).view(1, -1) # shape: (1, nu*T_p)\n",
    "        y_ini_tensor = torch.as_tensor(y_ini, dtype=torch.float32).view(1, -1) # shape: (1, ny*T_p)\n",
    "        e_u_tensor = torch.as_tensor(e_u, dtype=torch.float32).view(1, -1) # shape: (1, nu)\n",
    "        e_y_tensor = torch.as_tensor(e_y, dtype=torch.float32).view(1, -1) # shape: (1, ny)\n",
    "        time_feature_tensor = torch.as_tensor(time_feature, dtype=torch.float32).view(1, -1)  # shape: (1, T_p+1)\n",
    "        Uf_tensor = torch.tensor(Uf, dtype=torch.float32, device=self.device)\n",
    "        \n",
    "        # Concatenate along the feature dimension\n",
    "        input_vec = torch.cat([u_ini_tensor, y_ini_tensor, e_u_tensor, e_y_tensor, time_feature_tensor], dim=1) # shape: (1, input_dim)\n",
    "        \n",
    "        g_opt = self.predict_gk(input_vec, Uf, Yf, time_flag)  # shape (K,1)\n",
    "        \n",
    "        # 2) Reconstruct u_hat, y_hat from Hankel blocks\n",
    "        u_hat = self.uf_clamp(g_opt, Uf_tensor, time_flag) # torch.tensor(Uf, dtype=torch.float32).to(g_opt.device) @ g_opt  # shape (nu*T_f,1)\n",
    "        y_hat = torch.tensor(Yf, dtype=torch.float32).to(g_opt.device) @ g_opt  # shape (ny*T_f,1)\n",
    "\n",
    "        return u_hat, y_hat, g_opt\n",
    "        \n",
    "    def train_dnn_for_deepc(self, dnn_model, dataloader, Up, Yp, Uf, Yf, num_epochs=1000, lr=1e-4, \n",
    "                            start_epoch=0, optimizer=None, checkpoint_path=None,\n",
    "                            save_every=100, loss_history=[]):\n",
    "        if optimizer is None:\n",
    "            optimizer = torch.optim.Adam(dnn_model.parameters(), lr=lr)\n",
    "            \n",
    "        dnn_model.train()\n",
    "        \n",
    "        Q_diag = self.create_block_diag(self.params[\"Q\"], self.params[\"T_f\"])\n",
    "        R_diag = self.create_block_diag(self.params[\"R\"], self.params[\"T_f\"])\n",
    "        \n",
    "        # Convert the (offline) Hankel block for the future to torch tensors.\n",
    "        Uf_tensor = torch.tensor(Uf, dtype=torch.float32).T  # shape: (K, nu*T_f)\n",
    "        Yf_tensor = torch.tensor(Yf, dtype=torch.float32).T  # shape: (K, ny*T_f)\n",
    "        \n",
    "        # Convert the weighting matrices Q and R once to torch tensors.\n",
    "        Q_tensor = torch.tensor(Q_diag, dtype=torch.float32)  # Q has shape (ny*T_f, ny*T_f)\n",
    "        R_tensor = torch.tensor(R_diag, dtype=torch.float32)  # R has shape (nu*T_f, nu*T_f)\n",
    "        \n",
    "        alpha_u_lb = torch.tensor(self.params[\"alpha_u_lb\"], dtype=torch.float32)  # shape: (nu*T_f, nu*T_f)\n",
    "        alpha_u_ub = torch.tensor(self.params[\"alpha_u_ub\"], dtype=torch.float32)\n",
    "        \n",
    "        P_y_lb = torch.tensor(self.params[\"P_y_lb\"], dtype=torch.float32)   # shape: (ny*T_f,)\n",
    "        P_y_ub = torch.tensor(self.params[\"P_y_ub\"], dtype=torch.float32)   # same shape\n",
    "        \n",
    "        total_epochs = start_epoch + num_epochs\n",
    "        \n",
    "        # Create a single tqdm progress bar\n",
    "        pbar = tqdm(total=total_epochs, desc=\"Training Epochs\", unit=\"epoch\")\n",
    "        \n",
    "        for epoch in range(start_epoch, total_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            total_samples = 0\n",
    "            \n",
    "            for batch_idx, (u_ini, y_ini, e_u, e_y, u_ref, y_ref, time_feature, time_flag) in enumerate(dataloader):\n",
    "                batch_size = u_ini.shape[0]\n",
    "                total_samples += batch_size\n",
    "                                \n",
    "                # Flatten and concatenate the inputs\n",
    "                u_ini_flat = u_ini.view(u_ini.size(0), -1)      # (batch, nu * T_p)\n",
    "                y_ini_flat = y_ini.view(y_ini.size(0), -1)      # (batch, ny * T_p)\n",
    "                e_u_flat = e_u.view(e_u.size(0), -1)            # (batch, nu)\n",
    "                e_y_flat = e_y.view(e_y.size(0), -1)            # (batch, ny)\n",
    "                time_feature_flat = time_feature.view(time_feature.size(0), -1) # (batch, T_p + 1)\n",
    "                \n",
    "                input_vec = torch.cat([u_ini_flat, y_ini_flat, e_u_flat, e_y_flat, time_feature_flat], dim=1)\n",
    "                \n",
    "                # 0-3. Use LSTM model w/ differentiable QP layer for training\n",
    "                pred_g = self.predict_gk(input_vec, Uf, Yf, time_flag) # time_flag\n",
    "                \n",
    "                # 1. Input tracking loss\n",
    "                pred_u = torch.matmul(pred_g, Uf_tensor) # (batch, nu * T_f)\n",
    "                u_ref_flat = u_ref.view(u_ref.size(0), -1)      # (batch, nu * T_f)\n",
    "                u_error = pred_u - u_ref_flat\n",
    "                loss_u = torch.sum(u_error * torch.matmul(u_error, R_tensor), dim=1)\n",
    "                \n",
    "                \n",
    "                # 2. Output tracking loss\n",
    "                pred_y = torch.matmul(pred_g, Yf_tensor) # (batch, ny * T_f)\n",
    "                y_ref_flat = y_ref.view(y_ref.size(0), -1)      # (batch, ny * T_f)\n",
    "                y_error = pred_y - y_ref_flat\n",
    "                loss_y = torch.sum(y_error * torch.matmul(y_error, Q_tensor), dim=1)\n",
    "                \n",
    "                # ================================================\n",
    "                # 3-1. Soft-constraint for input\n",
    "                \n",
    "                # daytime / nighttime index\n",
    "                is_daytime = (time_flag[0].item() == 1) # is_daytime = 1: daytime, is_daytime = 0: nighttime\n",
    "                \n",
    "                u_min_tensor = torch.tensor(self.params[\"u_min\"], dtype=torch.float32).unsqueeze(0)  # shape: (1, nu*T_f)\n",
    "                u_max_tensor = torch.tensor(self.params[\"u_max\"], dtype=torch.float32).unsqueeze(0)\n",
    "                \n",
    "                if not is_daytime:\n",
    "                    u_max_tensor[0, 3] = 0\n",
    "                \n",
    "                violation_u_lb = F.relu(u_min_tensor - pred_u) # broadcasting is applied to u_min_tensor, u_max_tensor for batch_size\n",
    "                violation_u_ub = F.relu(pred_u - u_max_tensor)\n",
    "                pen_u_lb = alpha_u_lb * (violation_u_lb**2).sum(dim=1)\n",
    "                pen_u_ub = alpha_u_ub * (violation_u_ub**2).sum(dim=1)\n",
    "                \n",
    "                loss_pu = pen_u_lb + pen_u_ub\n",
    "                # ================================================\n",
    "                \n",
    "                # ================================================\n",
    "                # 3-2. Soft-constraint for state                \n",
    "                def get_bound(param_day, param_night):\n",
    "                    try:\n",
    "                        return self.p.get_param(param_night)\n",
    "                    except Exception:\n",
    "                        return self.p.get_param(param_day)\n",
    "                \n",
    "                y_min_vals = [\n",
    "                    self.p.get_param(\"Ti_min_day\") if is_daytime else get_bound(\"Ti_min_day\", \"Ti_min_night\"),\n",
    "                    self.p.get_param(\"Hi_min_day\") if is_daytime else get_bound(\"Hi_min_day\", \"Hi_min_night\"),\n",
    "                    self.p.get_param(\"Ci_min_day\") if is_daytime else get_bound(\"Ci_min_day\", \"Ci_min_night\"),\n",
    "                    self.p.get_param(\"Dw_min\"),\n",
    "                    self.p.get_param(\"Dw_min\")\n",
    "                ]\n",
    "                y_max_vals = [\n",
    "                    self.p.get_param(\"Ti_max_day\") if is_daytime else get_bound(\"Ti_max_day\", \"Ti_max_night\"),\n",
    "                    self.p.get_param(\"Hi_max_day\") if is_daytime else get_bound(\"Hi_max_day\", \"Hi_max_night\"),\n",
    "                    self.p.get_param(\"Ci_max_day\") if is_daytime else get_bound(\"Ci_max_day\", \"Ci_max_night\"),\n",
    "                    self.p.get_param(\"Dw_max\"),\n",
    "                    self.p.get_param(\"Dw_max\")\n",
    "                ]\n",
    "                \n",
    "                y_min_vals = np.array(y_min_vals, dtype=np.float32)\n",
    "                y_max_vals = np.array(y_max_vals, dtype=np.float32)\n",
    "                \n",
    "                y_min_vals = self.min_max_scale(y_min_vals, self.params[\"x_min_value_scaling\"], self.params[\"x_max_value_scaling\"])\n",
    "                y_max_vals = self.min_max_scale(y_max_vals, self.params[\"x_min_value_scaling\"], self.params[\"x_max_value_scaling\"])\n",
    "                \n",
    "                y_min_tensor = torch.tensor(y_min_vals, dtype=torch.float32, device=pred_y.device).repeat(1, self.params[\"T_f\"])\n",
    "                y_max_tensor = torch.tensor(y_max_vals, dtype=torch.float32, device=pred_y.device).repeat(1, self.params[\"T_f\"])\n",
    "                \n",
    "                violation_y_lb = F.relu(y_min_tensor - pred_y)\n",
    "                violation_y_ub = F.relu(pred_y - y_max_tensor)\n",
    "                # pen_y_lb = alpha_y_lb * (violation_y_lb**2).sum(dim=1)\n",
    "                # pen_y_ub = alpha_y_ub * (violation_y_ub**2).sum(dim=1)\n",
    "                \n",
    "                pen_y_lb = (P_y_lb * violation_y_lb**2).sum(dim=1)\n",
    "                pen_y_ub = (P_y_ub * violation_y_ub**2).sum(dim=1)\n",
    "                \n",
    "                loss_py = pen_y_lb + pen_y_ub\n",
    "                \n",
    "                loss_p_total = loss_pu + loss_py\n",
    "                # ================================================\n",
    "                \n",
    "                # ================================================\n",
    "                # 3-2. Soft-constraint for unscaled variables (unit: [℃], [RH], [ppm])\n",
    "                pred_y_3d = pred_y.view(batch_size, self.params[\"T_f\"], self.params[\"ny\"])   # e.g. (32, 2, 5)\n",
    "                \n",
    "                Xmin = torch.tensor(self.params[\"x_min_value_scaling\"], device=pred_y.device)\n",
    "                Xmax = torch.tensor(self.params[\"x_max_value_scaling\"], device=pred_y.device)\n",
    "                Xmin = Xmin.view(1, 1, self.params[\"ny\"])\n",
    "                Xmax = Xmax.view(1, 1, self.params[\"ny\"])\n",
    "                \n",
    "                pred_y_unscale = pred_y_3d * (Xmax - Xmin) + Xmin # unscaling shape: (batch, Tf, ny)\n",
    "                \n",
    "                # Select the correct RH bounds:\n",
    "                if time_flag[0].item() == 1:  # daytime\n",
    "                    RH_min, RH_max = self.p.get_param(\"RHi_min_day\"), self.p.get_param(\"RHi_max_day\")\n",
    "                    Ti_min, Ti_max = self.p.get_param(\"Ti_min_day\"), self.p.get_param(\"Ti_max_day\")\n",
    "                    Ci_min, Ci_max = self.p.get_param(\"Ci_min_day_ppm\"), self.p.get_param(\"Ci_max_day_ppm\")\n",
    "                else:                        # nighttime\n",
    "                    RH_min, RH_max = self.p.get_param(\"RHi_min_night\"), self.p.get_param(\"RHi_max_night\")\n",
    "                    Ti_min, Ti_max = self.p.get_param(\"Ti_min_night\"), self.p.get_param(\"Ti_max_night\")\n",
    "                    Ci_min, Ci_max = self.p.get_param(\"Ci_min_night_ppm\"), self.p.get_param(\"Ci_max_night_ppm\")\n",
    "                \n",
    "                Ti = pred_y_unscale[:, :, 0]                             # [°C]\n",
    "                Hi = pred_y_unscale[:, :, 1]                             # [kg/m³]\n",
    "                Ci = pred_y_unscale[:, :, 2]                             # [kg/m³]\n",
    "                Ci_ppm = Ci * (24.45 / self.p.get_param(\"m_co2\")) * 1E3  # [ppm]\n",
    "                \n",
    "                Hi_sat = (1.0272 * Ti - 1.8959) * 1e-3  # [kg/m³]\n",
    "                RHi    = (Hi / Hi_sat) * 100            # [%]\n",
    "                \n",
    "                # temperature violation\n",
    "                viol_T_lb = F.relu(Ti_min - Ti)                        # (batch, Tf)\n",
    "                viol_T_ub = F.relu(Ti - Ti_max)\n",
    "                loss_T    = self.params[\"lambda_T\"] * (viol_T_lb**2 + viol_T_ub**2).sum(dim=1)   # (batch,)\n",
    "                \n",
    "                # RH violation\n",
    "                viol_RH_lb = F.relu(RH_min - RHi)   # (batch, T_f)\n",
    "                viol_RH_ub = F.relu(RHi  - RH_max)\n",
    "                loss_RH = self.params[\"lambda_RH\"] * (viol_RH_lb**2 + viol_RH_ub**2).sum(dim=1)  \n",
    "                \n",
    "                # CO₂ violation\n",
    "                viol_C_lb = F.relu(Ci_min - Ci_ppm)\n",
    "                viol_C_ub = F.relu(Ci_ppm - Ci_max)\n",
    "                loss_CO2  = self.params[\"lambda_CO2\"] * (viol_C_lb**2 + viol_C_ub**2).sum(dim=1)\n",
    "                # ================================================\n",
    "                \n",
    "                \n",
    "                # ================================================\n",
    "                # 4. L2 regularization\n",
    "                loss_reg = 0.0\n",
    "                for param in dnn_model.parameters():\n",
    "                    loss_reg += torch.norm(param, 2) ** 2\n",
    "                loss_reg = self.params[\"lambda_reg\"] * loss_reg\n",
    "                # ================================================\n",
    "                \n",
    "                # ================================================\n",
    "                # 5. Energy minimization\n",
    "                pred_u_reshape = pred_u.view(pred_u.size(0), self.params[\"T_f\"], self.params[\"nu\"])\n",
    "                \n",
    "                loss_e = self.compute_stage_cost(pred_u_reshape.reshape(-1, self.params[\"nu\"]), dt=600)\n",
    "                loss_e = self.params[\"lambda_e\"] * loss_e.view(pred_u.size(0), self.params[\"T_f\"]).mean(dim=1)\n",
    "                # ================================================\n",
    "                \n",
    "                # ================================================\n",
    "                # 6. Crop yield maximization\n",
    "                pred_y_reshape = pred_y.view(pred_y.size(0), self.params[\"T_f\"], self.params[\"ny\"])\n",
    "                yield_value = pred_y_reshape[:, -1, 3] + pred_y_reshape[:, -1, 4]\n",
    "                loss_c = self.params[\"lambda_c\"] * -yield_value # (batch, )\n",
    "                # ================================================\n",
    "                \n",
    "                \n",
    "                # ================================================\n",
    "                # 7. Total loss\n",
    "                total_loss = torch.mean(loss_y + loss_u + loss_p_total) \\\n",
    "                                + loss_T.mean() \\\n",
    "                                + loss_RH.mean() \\\n",
    "                                + loss_CO2.mean() \\\n",
    "                                + loss_reg \\\n",
    "                                + torch.mean(loss_e) \\\n",
    "                                + torch.mean(loss_c)\n",
    "                # ================================================\n",
    "                \n",
    "                # if batch_idx % 20 == 0:\n",
    "                #     print(f\"Daytime index: {is_daytime}\")\n",
    "                #     print(f\"Epoch {epoch}, Batch {batch_idx}:\")\n",
    "                #     print(f\"Tracking: y={loss_y.mean().item():.2f}, u={loss_u.mean().item():.2f}, pu={loss_pu.mean().item():.2f}\")\n",
    "                #     print(f\"Penalties: T={loss_T.mean().item():.2f}, RH={loss_RH.mean().item():.2f}, CO2={loss_CO2.mean().item():.2f}\")\n",
    "                #     print(f\"Other: reg={loss_reg.item():.2f}, e={loss_e.mean().item():.2f}, c={loss_c.mean().item():.2f}\")\n",
    "                #     print(f\"Violations: T={viol_T_lb.mean().item():.2f}/{viol_T_ub.mean().item():.2f}, \"\n",
    "                #           f\"RH={viol_RH_lb.mean().item():.2f}/{viol_RH_ub.mean().item():.2f}, \"\n",
    "                #           f\"CO2={viol_C_lb.mean().item():.2f}/{viol_C_ub.mean().item():.2f}\")\n",
    "                #     print(f\"Scaled y: {pred_y[0].detach().cpu().numpy()}\")\n",
    "                #     print(f\"Unscaled T_i: {Ti[0,0].item():.2f}, RH_i: {RHi[0,0].item():.2f}, Ci_ppm: {Ci_ppm[0,0].item():.2f}\")\n",
    "                \n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                total_loss.backward()\n",
    "                \n",
    "                # gradient clipping\n",
    "                # grad_norm = torch.nn.utils.clip_grad_norm_(dnn_model.parameters(), max_norm=1.0) # max_norm=10.0\n",
    "                \n",
    "                # if batch_idx % 20 == 0:\n",
    "                #     print(f\"[Debug] grad norm before clipping: {grad_norm:.4f}\")\n",
    "                \n",
    "                \n",
    "                optimizer.step()\n",
    "                epoch_loss += total_loss.item() * batch_size\n",
    "                \n",
    "            avg_loss = epoch_loss / total_samples\n",
    "            loss_history.append(avg_loss)\n",
    "            \n",
    "            # Update the progress bar's postfix and increment it by 1 epoch\n",
    "            pbar.set_postfix(loss=f\"{avg_loss:.5f}\")\n",
    "            pbar.update(1)\n",
    "            \n",
    "            if checkpoint_path is not None and (epoch + 1) % save_every == 0:\n",
    "                save_dict = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_state_dict': dnn_model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_history': loss_history,\n",
    "                }\n",
    "                torch.save(save_dict, checkpoint_path)\n",
    "                print(f\"Checkpoint saved at epoch {epoch+1} to {checkpoint_path}\")\n",
    "            \n",
    "        print(\"Training complete.\")\n",
    "        return dnn_model, loss_history\n",
    "    \n",
    "    def get_first_control(self, u_opt):\n",
    "        # Reshape\n",
    "        u_opt_2d = u_opt.reshape(self.params[\"T_f\"], self.params[\"nu\"]) # shape (Tf, nu)\n",
    "        # The first row => the next control\n",
    "        return u_opt_2d[0, :]\n",
    "    \n",
    "    def get_first_state(self, y_opt):\n",
    "        # Reshape\n",
    "        y_opt_2d = y_opt.reshape(self.params[\"T_f\"], self.params[\"ny\"])  # shape (Tf, nu)\n",
    "        # The first row => the next control\n",
    "        return y_opt_2d[0, :]\n",
    "    \n",
    "    def min_max_scale(self, X, X_min, X_max):\n",
    "        # Avoid division by zero if X_max == X_min. Add small epsilon if needed.\n",
    "        return (X - X_min) / (X_max - X_min + 1e-12)\n",
    "\n",
    "    def min_max_unscale(self, X_scaled, X_min, X_max):\n",
    "        return X_scaled * (X_max - X_min) + X_min\n",
    "\n",
    "    def evaluate_validation(self, validation_loader):\n",
    "        if self.Uf is None or self.Yf is None:\n",
    "            raise ValueError(\"Hankel matrices Uf and Yf must be set before evaluation. Call set_hankel_matrices().\")\n",
    "        \n",
    "        # Convert Uf and Yf to torch tensors for reconstruction.\n",
    "        Uf_tensor = torch.tensor(self.Uf, dtype=torch.float32).T  # shape: (K, nu*T_f)\n",
    "        Yf_tensor = torch.tensor(self.Yf, dtype=torch.float32).T  # shape: (K, ny*T_f)\n",
    "        \n",
    "        self.dnn.eval()\n",
    "        losses = []\n",
    "        for (u_ini, y_ini, e_u, e_y, u_ref, y_ref, time_feature) in validation_loader:\n",
    "            # Flatten and concatenate the inputs.\n",
    "            u_ini_flat = u_ini.view(u_ini.size(0), -1)\n",
    "            y_ini_flat = y_ini.view(y_ini.size(0), -1)\n",
    "            e_u_flat = e_u.view(e_u.size(0), -1)            # shape (batch, nu)\n",
    "            e_y_flat = e_y.view(e_y.size(0), -1)            # shape (batch, ny)\n",
    "            u_ref_flat = u_ref.view(u_ref.size(0), -1)\n",
    "            y_ref_flat = y_ref.view(y_ref.size(0), -1)\n",
    "            time_feature_flat = time_feature.view(time_feature.size(0), -1)\n",
    "            \n",
    "            input_vec = torch.cat([u_ini_flat, y_ini_flat, e_u_flat, e_y_flat, time_feature_flat], dim=1)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                pred_g = self.dnn(input_vec)  # shape: (batch, K)\n",
    "            \n",
    "            # Reconstruct the predicted trajectories.\n",
    "            pred_u = torch.matmul(pred_g, Uf_tensor)  # shape: (batch, nu*T_f)\n",
    "            pred_y = torch.matmul(pred_g, Yf_tensor)   # shape: (batch, ny*T_f)\n",
    "            \n",
    "            # Compute the error between the predicted and reference trajectories.\n",
    "            u_error = pred_u - u_ref_flat\n",
    "            y_error = pred_y - y_ref_flat\n",
    "            \n",
    "            # Use a simple mean squared error (MSE) as the performance metric.\n",
    "            loss_batch = torch.mean(u_error**2 + y_error**2).item()\n",
    "            # loss_batch = torch.mean(u_error**2).item()\n",
    "            losses.append(loss_batch)\n",
    "        \n",
    "        return np.mean(losses)\n",
    "    \n",
    "    def uf_clamp(self, g, Uf_tensor, time_flag):\n",
    "        u_raw = torch.matmul(g, Uf_tensor.T)                     # (batch, nu*Tf)\n",
    "        u_min_tensor = torch.as_tensor(self.params[\"u_min\"], dtype=g.dtype, device=g.device)\n",
    "        u_max_tensor = torch.as_tensor(self.params[\"u_max\"], dtype=g.dtype, device=g.device)\n",
    "        \n",
    "        if time_flag == 0: # nighttime\n",
    "            u_max_tensor[3] = 0   # lighting -> 0\n",
    "            \n",
    "        return torch.clamp(u_raw, u_min_tensor, u_max_tensor)                  # (batch, nu*Tf)\n",
    "    \n",
    "    \n",
    "    def create_block_diag(self, base_matrix, horizon):\n",
    "        return block_diag(*[base_matrix for _ in range(horizon)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "133821ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "class DeepDeePCDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        self.data_list = data_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        u_ini, y_ini, e_u, e_y, u_ref, y_ref, time_feature, time_flag = self.data_list[idx]\n",
    "        return (torch.tensor(u_ini, dtype=torch.float32),\n",
    "                torch.tensor(y_ini, dtype=torch.float32),\n",
    "                torch.tensor(e_u, dtype=torch.float32),\n",
    "                torch.tensor(e_y, dtype=torch.float32),\n",
    "                torch.tensor(u_ref, dtype=torch.float32),\n",
    "                torch.tensor(y_ref, dtype=torch.float32),\n",
    "                torch.tensor(time_feature, dtype=torch.float32),\n",
    "                torch.tensor(time_flag, dtype=torch.float32),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "766ae038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scale(X, X_min, X_max):\n",
    "    # Avoid division by zero if X_max == X_min. Add small epsilon if needed.\n",
    "    return (X - X_min) / (X_max - X_min + 1e-12)\n",
    "\n",
    "def min_max_unscale(X_scaled, X_min, X_max):\n",
    "    return X_scaled * (X_max - X_min) + X_min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1eb2d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNPredictor_LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, lstm_hyperparams, seq_length):\n",
    "        super(DNNPredictor_LSTM, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        if input_dim % seq_length != 0:\n",
    "            raise ValueError(\"input_dim must be divisible by seq_length\")\n",
    "        self.feature_dim = input_dim // seq_length  # e.g., 70 // 7 = 10\n",
    "        \n",
    "        hidden_size = lstm_hyperparams.get(\"hidden_size\")\n",
    "        num_layers = lstm_hyperparams.get(\"num_layers\")\n",
    "        dropout_rate = lstm_hyperparams.get(\"dropout\")\n",
    "        \n",
    "        # LSTM layer: input shape (batch, seq_length, feature_dim)\n",
    "        self.lstm = nn.LSTM(input_size=self.feature_dim, hidden_size=hidden_size, \n",
    "                            num_layers=num_layers, batch_first=True, dropout=dropout_rate)\n",
    "        \n",
    "        # Final linear projection to output_dim\n",
    "        self.fc_out = nn.Linear(hidden_size, output_dim)\n",
    "        self.bn_out = nn.BatchNorm1d(output_dim, momentum=0.05) # slower updates\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        # Reshape x to (batch, seq_length, feature_dim)\n",
    "        x = x.view(batch_size, self.seq_length, self.feature_dim)\n",
    "        \n",
    "        # Pass through LSTM; we use only the last hidden state.\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        # h_n has shape (num_layers, batch, hidden_size). Use the last layer's hidden state.\n",
    "        h_last = h_n[-1]  # shape (batch, hidden_size)\n",
    "        \n",
    "        # Final linear mapping to output dimension.\n",
    "        out = self.fc_out(h_last)  # shape (batch, output_dim)\n",
    "        return self.bn_out(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6493daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class FigurePlotter:\n",
    "    \"\"\"\n",
    "    Compact plotting of states and control inputs for comparison.\n",
    "    \"\"\"\n",
    "    def __init__(self, params):\n",
    "        self.p = params\n",
    "\n",
    "    def _to_days(self, t_s):\n",
    "        return t_s / 3600.0 / 24.0\n",
    "\n",
    "    def plot_states(self, time_s, x_deepc, x_nmpc, x_min=None, x_max=None,\n",
    "                    titles=None):\n",
    "        \"\"\"\n",
    "        Plot Deep DeePC vs. NMPC states side by side.\n",
    "        Optionally include min/max bounds.\n",
    "        \"\"\"\n",
    "        t = self._to_days(time_s)\n",
    "        n_vars = x_deepc.shape[1]\n",
    "        titles = titles or [f\"Var{i}\" for i in range(n_vars)]\n",
    "        fig, axs = plt.subplots(1, n_vars, figsize=(4 * n_vars, 3), sharex=True)\n",
    "        for i, ax in enumerate(axs):\n",
    "            ax.plot(t, x_nmpc[:, i], '--', label='NMPC')\n",
    "            ax.plot(t, x_deepc[:, i], '-', label='Deep DeePC')\n",
    "            if x_min is not None and x_max is not None:\n",
    "                ax.plot(t, x_min[:, i], 'r--')\n",
    "                ax.plot(t, x_max[:, i], 'r--')\n",
    "            ax.set(title=titles[i])\n",
    "            ax.legend(loc='upper left', fontsize='small')\n",
    "            ax.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_controls(self, time_s, u_deepc, u_nmpc, titles=None):\n",
    "        \"\"\"\n",
    "        Plot step comparison of control inputs.\n",
    "        \"\"\"\n",
    "        t = self._to_days(time_s)\n",
    "        n_ctrl = u_deepc.shape[1]\n",
    "        titles = titles or [f\"u{i}\" for i in range(n_ctrl)]\n",
    "        fig, axs = plt.subplots(1, n_ctrl, figsize=(3 * n_ctrl, 3), sharex=True)\n",
    "        for i, ax in enumerate(axs):\n",
    "            ax.step(t, u_nmpc[:, i], '--', where='post', label='NMPC', alpha=0.5)\n",
    "            ax.step(t, u_deepc[:, i], '-', where='post', label='Deep DeePC')\n",
    "            ax.set(title=titles[i])\n",
    "            ax.legend(loc='upper left', fontsize='small')\n",
    "            ax.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5adaf55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_data(file_path, data):\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "    print(f\"Data successfully saved to {file_path}\")\n",
    "    \n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    print(f\"Data successfully loaded from {file_path}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96f7ba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_daytime_index(solar_radiation, window_size=15, Io_low=50.0, Io_high=100.0):\n",
    "    weights = np.ones(window_size) / window_size\n",
    "    Io_avg = np.convolve(solar_radiation, weights, mode='valid')\n",
    "    \n",
    "    # Pad the array to match original length, filling edges appropriately\n",
    "    pad_start = (window_size - 1) // 2\n",
    "    pad_end = window_size - 1 - pad_start\n",
    "    Io_avg = np.pad(Io_avg, (pad_start, pad_end), mode='edge')\n",
    "    \n",
    "    # Binary classification using midpoint threshold\n",
    "    threshold = (Io_low + Io_high) / 2  # 75.0\n",
    "    daytime_index = np.where(Io_avg >= threshold, 1.0, 0.0)\n",
    "    \n",
    "    # Reshape to (total_steps, 1) as in your original code\n",
    "    return daytime_index.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3546d566",
   "metadata": {},
   "source": [
    "## 2. Simulation Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d303c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from ./inputs/OSU_30days_N2_v2.pkl\n"
     ]
    }
   ],
   "source": [
    "dataset_days = 30\n",
    "\n",
    "N = 2\n",
    "filename = f\"./inputs/OSU_{dataset_days}days_N{N}_v2.pkl\"\n",
    "data = load_data(filename)\n",
    "\n",
    "dt = 600\n",
    "time_per_day = np.arange(0, 86400 + dt, dt)\n",
    "num_steps_per_day = len(time_per_day) - 1\n",
    "\n",
    "total_days = 15 # 5\n",
    "num_data = num_steps_per_day * total_days\n",
    "\n",
    "x = data[\"x\"][1:num_data+1,:]  # (T, nx) remove the first element, x0\n",
    "u = data[\"u\"][:num_data,:]     # (T, nu)\n",
    "o = data[\"df_outdoor\"].iloc[:num_data, [0, 1, 3]].values.astype(float) # [To, Ho, Io]\n",
    "\n",
    "daytime_idx = gen_daytime_index(o[:,2], window_size=15, Io_low=50.0, Io_high=100.0)\n",
    "\n",
    "x_min_value = x.min(axis=0, keepdims=True)  # shape (1, ny)\n",
    "x_max_value = x.max(axis=0, keepdims=True)\n",
    "\n",
    "x_scaled = min_max_scale(x, x_min_value, x_max_value)\n",
    "\n",
    "p = GreenhouseParams()\n",
    "model = CropClimateModel(p)\n",
    "plotter = FigurePlotter(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "489304f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import block_diag\n",
    "\n",
    "T = len(x)     # total number of dataset\n",
    "T_p = 7        # past horizon\n",
    "T_f = 3        # future horizon\n",
    "L = T_p + T_f  # (past + future) horizon\n",
    "K = T - L + 1  # number of columns in the Hankel\n",
    "\n",
    "nx = x.shape[1]\n",
    "ny = x.shape[1]\n",
    "nu = u.shape[1]\n",
    "\n",
    "# Choose a candidate pair (for example, the third candidate in each range)\n",
    "lambda_Q = 1e1  # 1e0\n",
    "lambda_R = 1e0 # 1e-1 # 5e0\n",
    "\n",
    "# Base weighting matrices\n",
    "# base_Q = np.eye(ny) #\n",
    "base_Q = np.diag([1e0, 1e0, 1e1, 1e0, 1e0])\n",
    "base_R = np.eye(nu) # np.diag([1e1, 1e1, 1e0, 2e-1, 1e0, 1e0, 5e-1])\n",
    "# base_R = np.diag([1e1, 1e0, 2e-1, 1e0, 5e-1]) # 1e2 * np.eye(nu * T_f) # 1e-2\n",
    "\n",
    "# Set Q and R using the chosen lambda values\n",
    "Q = lambda_Q * base_Q\n",
    "R = lambda_R * base_R\n",
    "\n",
    "# penalty for soft constraint terms\n",
    "alpha_u_lb = 0e1 # 1e+1 # 5e0\n",
    "alpha_u_ub = 0e1 # 1e+1\n",
    "alpha_y_lb = 1e1 # 1e+1\n",
    "alpha_y_ub = 1e1 # 1e+1\n",
    "\n",
    "# penalty for relative humidity\n",
    "# lambda_T = 1e0 # 1e0\n",
    "# lambda_RH = 3e0\n",
    "# lambda_CO2 = 5e-3 # 1e1 # 5e-1 # 2e-1 # 5e-2\n",
    "\n",
    "lambda_T = 1e-2 # 1e0\n",
    "lambda_RH = 1e-2\n",
    "lambda_CO2 = 1e-3 # 1e1 # 5e-1 # 2e-1 # 5e-2\n",
    "\n",
    "\n",
    "# energy cost and crop yield terms\n",
    "lambda_e = 1e0 # 5e1 # 1e0\n",
    "lambda_c = 2e-1 # 1e1\n",
    "\n",
    "P_u_lb = np.eye(nu * T_f) * alpha_u_lb\n",
    "P_u_ub = np.eye(nu * T_f) * alpha_u_ub\n",
    "# P_y_lb = np.eye(ny * T_f) * alpha_y_lb\n",
    "# P_y_ub = np.eye(ny * T_f) * alpha_y_ub\n",
    "P_y_lb = np.tile([1, 1, 1e1, 1, 1], T_f) * alpha_y_lb # np.eye(ny * T_f) * alpha_y_lb\n",
    "P_y_ub = np.tile([1, 1, 1e1, 1, 1], T_f) * alpha_y_ub # np.eye(ny * T_f) * alpha_y_lb\n",
    "\n",
    "u_min = np.zeros(nu * T_f)\n",
    "u_max = np.ones(nu * T_f)\n",
    "\n",
    "lambda_reg = 1e-4 # l2 regularization hyperparameter for loss function\n",
    "k_idx_diffQP = 10 # Hybrid training strategy index\n",
    "\n",
    "params = {\n",
    "        \"T\": T,\n",
    "        \"T_p\": T_p,\n",
    "        \"T_f\": T_f,\n",
    "        \"L\": L,\n",
    "        \"K\": K,\n",
    "        \"nx\": nx,\n",
    "        \"ny\": ny,\n",
    "        \"nu\": nu,\n",
    "        \"Q\": Q,\n",
    "        \"R\": R,\n",
    "        \"lambda_T\": lambda_T,\n",
    "        \"lambda_RH\": lambda_RH,\n",
    "        \"lambda_CO2\": lambda_CO2,\n",
    "        \"lambda_reg\": lambda_reg,\n",
    "        \"lambda_e\": lambda_e, # weight for energy minimization\n",
    "        \"lambda_c\": lambda_c, # weight for crop yield maximization\n",
    "        \"alpha_u_lb\": alpha_u_lb,\n",
    "        \"alpha_u_ub\": alpha_u_ub,\n",
    "        \"alpha_y_lb\": alpha_y_lb,\n",
    "        \"alpha_y_ub\": alpha_y_ub,\n",
    "        \"P_y_lb\": P_y_lb,\n",
    "        \"P_y_ub\": P_y_ub,\n",
    "        \"u_min\": u_min,\n",
    "        \"u_max\": u_max,\n",
    "        \"x_min_value_scaling\": x_min_value,\n",
    "        \"x_max_value_scaling\": x_max_value,\n",
    "        \"k_idx_diffQP\": k_idx_diffQP,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bdc9c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinsungkim/anaconda3/envs/jskim_deepc_v4/lib/python3.9/site-packages/cvxpy/reductions/solvers/solving_chain.py:254: UserWarning: Your problem has too many parameters for efficient DPP compilation. We suggest setting 'ignore_dpp = True'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lstm_hyperparams = {\n",
    "    \"batch_size\": 64,  # For example\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 4,\n",
    "    \"dropout\": 0.2,\n",
    "}\n",
    "\n",
    "input_dim = (nu + ny + 1) * (T_p + 1)  # e.g., 70\n",
    "output_dim = K                         # e.g., 1417\n",
    "seq_length = T_p + 1                   # e.g., 7\n",
    "\n",
    "\n",
    "model_type = \"lstm\"               # Options: \"dnn\", \"lstm\", \"bilstm\", \"gru\"\n",
    "dnn_model = DNNPredictor_LSTM(input_dim, output_dim, lstm_hyperparams, seq_length=seq_length)\n",
    "\n",
    "deep_deepc = DeepDeePC(p, params, dnn_model)\n",
    "Up, Yp, Uf, Yf = deep_deepc.build_hankel_matrices(x_scaled, u)\n",
    "\n",
    "deep_deepc.set_hankel_matrices(Uf, Yf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3d95d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "class TimeFlagSampler(Sampler):\n",
    "    def __init__(self, data_source, batch_size):\n",
    "        self.data_source = data_source\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.day_indices = []\n",
    "        self.night_indices = []\n",
    "        for idx in range(len(data_source)):\n",
    "            sample = data_source[idx]\n",
    "            \n",
    "            if isinstance(sample[-1], torch.Tensor):\n",
    "                flag_tensor = sample[-1].view(-1)\n",
    "                time_flag = int(flag_tensor[0].item())\n",
    "            else:\n",
    "                time_flag = int(sample[-1])\n",
    "            \n",
    "            if time_flag == 1:\n",
    "                self.day_indices.append(idx)\n",
    "            else:\n",
    "                self.night_indices.append(idx)\n",
    "        \n",
    "        # Debug distribution\n",
    "        print(f\"Number of daytime indices: {len(self.day_indices)}\")\n",
    "        print(f\"Number of nighttime indices: {len(self.night_indices)}\")\n",
    "        \n",
    "        self.batches = []\n",
    "\n",
    "        # Create batches for daytime indices, yielding incomplete batches if needed.\n",
    "        random.shuffle(self.day_indices)\n",
    "        for i in range(0, len(self.day_indices), batch_size):\n",
    "            batch = self.day_indices[i:i+batch_size]\n",
    "            if len(batch) > 0:\n",
    "                self.batches.append(batch)\n",
    "\n",
    "        # Create batches for nighttime indices.\n",
    "        random.shuffle(self.night_indices)\n",
    "        for i in range(0, len(self.night_indices), batch_size):\n",
    "            batch = self.night_indices[i:i+batch_size]\n",
    "            if len(batch) > 0:\n",
    "                self.batches.append(batch)\n",
    "                \n",
    "        # Shuffle the order of mini-batches so training sees a mix of day and night.\n",
    "        random.shuffle(self.batches)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.batches:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b6a1525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of dataset: 422 where # of training: 337, # of validation: 85\n",
      "Number of daytime indices: 182\n",
      "Number of nighttime indices: 155\n"
     ]
    }
   ],
   "source": [
    "# ==== Offline Training Data Generation ====\n",
    "# We generate training samples by sliding a window over the dataset.\n",
    "total_dataset_list = []\n",
    "x_min_day, x_max_day, x_min_night, x_max_night = p.set_min_max()\n",
    "\n",
    "# For each time index where full past and future windows exist:\n",
    "for i in range(T_p, T - T_f):\n",
    "    u_ini = u[i-T_p : i, :].reshape(-1, 1)\n",
    "    u_ref = u[i : i+T_f, :].reshape(-1, 1)\n",
    "    y_ini = x_scaled[i-T_p+1 : i+1, :].reshape(-1, 1)\n",
    "    y_ref = x_scaled[i+1 : i+T_f+1, :].reshape(-1, 1)\n",
    "    \n",
    "    e_u = u_ref[0:nu] - u_ini[-nu:]\n",
    "    e_y = y_ref[0:ny] - y_ini[-ny:]\n",
    "     \n",
    "    time_feature = daytime_idx[i-T_p:i+1].reshape(-1, 1)\n",
    "    time_flag = np.array([int(time_feature[-1, 0])])\n",
    "\n",
    "    # The DeePC references are taken as u_ref and y_ref.\n",
    "    total_dataset_list.append((u_ini, y_ini, e_u, e_y, u_ref, y_ref, time_feature, time_flag))\n",
    "\n",
    "total_dataset = DeepDeePCDataset(total_dataset_list)\n",
    "total_size = len(total_dataset_list)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = total_size - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(total_dataset, [train_size, val_size])\n",
    "print(f\"Total # of dataset: {total_size} where # of training: {train_size}, # of validation: {val_size}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_sampler=TimeFlagSampler(train_dataset, lstm_hyperparams[\"batch_size\"])) # shuffle = True\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=lstm_hyperparams[\"batch_size\"], shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880254b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoint/lstm.pth\"\n",
    "optimizer = torch.optim.Adam(dnn_model.parameters(), lr=1e-4)\n",
    "\n",
    "num_training_epochs = 2000\n",
    "total_epoch = num_training_epochs\n",
    "# dnn_model, loss_history = deep_deepc.train_dnn_for_deepc(dnn_model, train_loader, Up, Yp, Uf, Yf, num_epochs=num_training_epochs, lr=5e-4, start_epoch=0)\n",
    "dnn_model, loss_history = deep_deepc.train_dnn_for_deepc(\n",
    "                            dnn_model, train_loader, Up, Yp, Uf, Yf, \n",
    "                            num_epochs=num_training_epochs, lr=1e-4, start_epoch=0,\n",
    "                            checkpoint_path=checkpoint_path, save_every=200\n",
    "                            ) # optimizer, loss_history\n",
    "\n",
    "dnn_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7286d7d",
   "metadata": {},
   "source": [
    "## 3. Online Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc21995",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "deep_deepc = DeepDeePC(p, params, dnn_model, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48be60dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Initialize matrices for states, controls, and cost function over all days\n",
    "y_total = np.zeros((total_days * num_steps_per_day + (T_p + 1), ny))\n",
    "y_model = np.zeros((total_days * num_steps_per_day + (T_p + 1), ny))\n",
    "u_total = np.zeros((total_days * num_steps_per_day + T_p, nu))\n",
    "g_total = np.zeros((total_days * num_steps_per_day + T_p, K))\n",
    "\n",
    "# Initialize min / max / reference values\n",
    "x_min_total = np.zeros((total_days * num_steps_per_day + 1, nx))\n",
    "x_max_total = np.zeros((total_days * num_steps_per_day + 1, nx))\n",
    "x_ref_total = np.zeros((total_days * num_steps_per_day + 1, nx))\n",
    "\n",
    "# For the very first step, assume nighttime references\n",
    "x_min_total[0, :] = x_min_night\n",
    "x_max_total[0, :] = x_max_night\n",
    "x_ref_total[0, :] = 0.5 * (x_min_night + x_max_night)\n",
    "\n",
    "J = np.zeros(total_days * num_steps_per_day)  # cost function per time steps\n",
    "\n",
    "# Set the initial condition\n",
    "# x0, u0 = p.set_initial()\n",
    "y_total[0, :] = x[T_p-1,:]\n",
    "y_model[0, :] = x[T_p-1,:]\n",
    "\n",
    "step_time = np.zeros(total_days * num_steps_per_day)\n",
    "day_time = np.zeros(total_days)\n",
    "\n",
    "# Moving average for solar radiation smoothing\n",
    "window_size = 15\n",
    "solar_window = np.zeros(window_size)\n",
    "window_index = 0\n",
    "\n",
    "Io_low = 50.0     # Nighttime threshold [W/m²]\n",
    "Io_high = 100.0   # Daytime threshold [W/m²]\n",
    "alpha = 0.0  # last-step interpolation weight\n",
    "ramp_steps = 10   # number of steps over which to go from nighttime to daytime\n",
    "\n",
    "# Start Simulation (Deep DeePC Online Implementation using trained DNN via offline)\n",
    "print(\"Starting online control simulation...\")\n",
    "\n",
    "# for day in range(1, 2):\n",
    "for day in range(1, total_days + 1):\n",
    "    day_start_time = time.time()\n",
    "    start_index = (day - 1) * num_steps_per_day\n",
    "      \n",
    "    # for k in range(1, T_p+2):\n",
    "    for k in range(1, num_steps_per_day + 1):\n",
    "        step_start_time = time.time()\n",
    "        global_index = start_index + (k-1) + T_p # T_p, T_p + 1, T_p + 2, ...\n",
    "        \n",
    "        # Define the constraints based on daytime / nighttime\n",
    "        ok = data[\"df_outdoor\"].iloc[global_index, [0, 1, 3]].values.astype(float)  # or however you get outside [To, Ho, Io]\n",
    "        \n",
    "        # Smooth solar radiation (Io) with moving average\n",
    "        solar_window[window_index] = ok[-1]  # Io\n",
    "        window_index = (window_index + 1) % window_size\n",
    "        Io_avg = np.mean(solar_window)\n",
    "        \n",
    "        if Io_avg <= Io_low:\n",
    "            alpha_target = 0.0  # Night\n",
    "        elif Io_avg >= Io_high:\n",
    "            alpha_target = 1.0  # Day\n",
    "        else:\n",
    "            alpha_target = (Io_avg - Io_low) / (Io_high - Io_low)  # Transition\n",
    "        \n",
    "        # 2. march alpha toward alpha_target by exactly 1/ramp_steps per step\n",
    "        step = 1.0 / ramp_steps\n",
    "        if alpha < alpha_target:\n",
    "            alpha = min(alpha + step, alpha_target)\n",
    "        elif alpha > alpha_target:\n",
    "            alpha = max(alpha - step, alpha_target)\n",
    "        # if alpha == alpha_target, it stays there\n",
    "        \n",
    "        # Interpolate state constraints and reference:\n",
    "        x_min = (1 - alpha) * x_min_night + alpha * x_min_day\n",
    "        x_max = (1 - alpha) * x_max_night + alpha * x_max_day\n",
    "        x_ref = 0.5 * (x_min + x_max)\n",
    "        x_ref[1] = (x_ref[1] / 100) * (1.0272 * x_ref[0] - 1.8959) * 1E-3\n",
    "        \n",
    "        # Reference values\n",
    "        u_ref = u[global_index : global_index + T_f, :].reshape(-1, 1)\n",
    "        y_ref = x_scaled[global_index + 1 : global_index + T_f + 1, :].reshape(-1, 1)\n",
    "        time_feature = daytime_idx[global_index-T_p:global_index+1].reshape(-1, 1)\n",
    "        time_flag = int(time_feature[-1, 0]) # Extract time_flag from the last element of time_feature\n",
    "        \n",
    "        # Initial & error values for DNN input\n",
    "        if k <= T_p:\n",
    "            u_ini = u[global_index - T_p : global_index, :].reshape(-1, 1)  # shape (nu*T_p,1)\n",
    "            y_ini = x_scaled[global_index - T_p + 1 : global_index + 1, :].reshape(-1, 1)  # shape (ny*T_p,1)\n",
    "            e_u = u_ref[0:nu] - u_ini[-nu:]\n",
    "            e_y = y_ref[0:ny] - y_ini[-ny:]\n",
    "        else:\n",
    "            u_ini = u[global_index - T_p : global_index, :].reshape(-1, 1)  # shape (nu*T_p,1)\n",
    "            y_ini = x_scaled[global_index - T_p : global_index, :].reshape(-1, 1)  # shape (ny*T_p,1)\n",
    "            \n",
    "            e_u = u_ref[0:nu] - u_ini[-nu:]\n",
    "            e_y = y_ref[0:ny] - y_ini[-ny:]\n",
    "            \n",
    "            # u_ini = u_total[global_index - 2 * T_p : global_index - T_p, :].reshape(-1, 1)  # shape (nu*T_p,1)\n",
    "            # y_ini = min_max_scale(y_model[global_index - 2 * T_p : global_index - T_p, :], x_min_value, x_max_value).squeeze().reshape(-1, 1)\n",
    "        \n",
    "        \n",
    "        # Determine the optimal solution via DeePC\n",
    "        u_opt, y_opt_scaled, g_opt = deep_deepc.solve_deep_deepc(Up, Yp, Uf, Yf, u_ini, y_ini, e_u, e_y, time_feature, time_flag)\n",
    "        \n",
    "        # y_opt = min_max_unscale(y_opt_scaled.reshape(-1, ny), x_min_value, x_max_value)\n",
    "        y_opt = min_max_unscale(y_opt_scaled.detach().reshape(-1, ny), x_min_value, x_max_value)\n",
    "        \n",
    "        u_total[global_index - T_p, :] = deep_deepc.get_first_control(u_opt.detach().cpu().numpy()) # u_opt[:nu,].T # Store control input to the control array\n",
    "        y_total[global_index - T_p + 1, :] = deep_deepc.get_first_state(y_opt.detach().cpu().numpy()) # y_opt[:ny,].T # Store control input to the control array\n",
    "        g_total[global_index - T_p, :] = g_opt.detach().cpu().numpy().T\n",
    "        \n",
    "        # Store min/max constraints for reference\n",
    "        x_min_total[global_index - T_p + 1, :] = x_min\n",
    "        x_max_total[global_index - T_p + 1, :] = x_max\n",
    "        x_ref_total[global_index - T_p + 1, :] = x_ref\n",
    "        \n",
    "        \n",
    "        # 4. Implement (xk, uk, ok) to the greenhouse model\n",
    "        # xk = min_max_unscale(xk_scaled, x_min_value, x_max_value).squeeze()\n",
    "        xk = y_model[global_index - T_p, :] # x[T_p-1,:] (in real, x[T_p]), ...\n",
    "        uk = u_total[global_index - T_p, :] # u[T_p]\n",
    "        ok = data[\"df_outdoor\"].iloc[global_index, [0, 1, 3]].values.astype(float)  # or however you get outside [To, Ho, Io]\n",
    "        \n",
    "        dxdt = model.rk4_gh(time_per_day[k], dt, xk, uk, ok)\n",
    "        x_next = xk + (dt / 6.0) * dxdt # closed-form results\n",
    "        \n",
    "        y_model[global_index - T_p + 1, :] = x_next\n",
    "        J[global_index - T_p] = deep_deepc.compute_stage_cost(uk, dt) # compute stage cost\n",
    "        \n",
    "        # Time for the time step\n",
    "        step_time[k-1] = time.time() - step_start_time\n",
    "        print(f\"--- DeePC Computation time for each k={k} of Day {day} completed in {step_time[k-1]:.4f} [s] ---\")\n",
    "\n",
    "    # Time for the full day\n",
    "    day_time[day-1] = time.time() - day_start_time\n",
    "    print(f\"--- Day {day} completed in {day_time[day-1]:.2f} [s] ---\")\n",
    "\n",
    "print(f\"------ Average computation time per step: {(np.mean(day_time)/num_steps_per_day):.3f} [s] ------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ac11e6",
   "metadata": {},
   "source": [
    "## 4. Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36255ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Build the full-time vector\n",
    "total_time_s = np.arange(0, total_days*86400 + dt, dt)  # shape (total_days*num_steps_per_day+1,)\n",
    "\n",
    "# 3) Plot the state variables\n",
    "# We assume x, x_min_total, x_max_total are the final arrays after simulation\n",
    "plotter.plot_states_compare(time_s=total_time_s,\n",
    "                            x_deepc=y_model[:len(total_time_s)], # y_total,\n",
    "                            x_nmpc=x[T_p-1:len(total_time_s)+T_p-1,:],\n",
    "                            x_min = x_min_total,\n",
    "                            x_max = x_max_total,\n",
    "                            title_str=\"Greenhouse Internal States (Deep DeePC vs NMPC)\")\n",
    "\n",
    "plotter.plot_controls_compare(time_s=total_time_s[1:],\n",
    "                            u_deepc=u_total[:len(total_time_s)-1],\n",
    "                            u_nmpc=u[T_p:len(total_time_s)+T_p-1,:],\n",
    "                            title_str=\"Control Input Comparison (Deep DeePC vs NMPC)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7637d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "J_acc = plotter.plot_costs_compare(time_s=total_time_s[1:],\n",
    "                   J_deepc=J,\n",
    "                   J_nmpc=data[\"J\"][T_p:len(J)+T_p],\n",
    "                   title_str=\"Costs Over Time\")\n",
    "\n",
    "C_heat, C_cool, C_light, C_fan, C_dehum, C_co2 = plotter.plot_component_costs(time_s=total_time_s[1:], u=u_total[:len(total_time_s)-1], dt=dt, title_str=\"Control Component Costs Over Time\") \n",
    "\n",
    "J_nmpc = data[\"J\"][T_p:len(J)+T_p]\n",
    "J_nmpc_acc = np.sum(J_nmpc) * p.get_param(\"A_s\")\n",
    "Dw_nmpc = x[len(total_time_s)+T_p-2,-1] + x[len(total_time_s)+T_p-2,-2]\n",
    "\n",
    "print(f\"--- [NMPC] Total Cost: {J_nmpc_acc:.2f} [$], Total crop dry weight: {Dw_nmpc:.6f} [kg/m²]\")\n",
    "print(f\"--- [Deep DeePC] Total Cost: {J_acc[-1]:.2f} [$], Total crop dry weight: {(y_model[len(total_time_s)-1,-2] + y_model[len(total_time_s)-1,-1]):.6f} [kg/m²]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jskim_deepc_v4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
